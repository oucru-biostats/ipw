\name{ipwtm}
\Rdversion{1.1}
\alias{ipwtm}
%- Also NEED an '\alias' for EACH other topic documented here.

\title{Estimate Inverse Probability Weights (Time Varying)}

\description{Estimate inverse probability weights to fit marginal structural models, with a time-varying exposure and time-varying confounders. Within each unit under observation this function computes inverse probability weights at each time point during follow-up. The exposure can be binomial, multinomial, ordinal or continuous. Both stabilized and unstabilized weights can be estimated.}

\usage{ipwtm(exposure, family, link, numerator = NULL, denominator, id,
       tstart, timevar, type, data, corstr = "ar1", trim = NULL, ...)}

\arguments{
\item{exposure}{vector, representing the exposure of interest. Both numerical and factor variables can be used. A binomial exposure variable should be coded using values \code{0}/\code{1}}
\item{family}{specifies a family of link functions, used to model the relationship between the variables in \code{numerator} or \code{denominator} and \code{exposure}, respectively. Valid alternatives are \code{"binomial"}, \code{"survival"}, \code{"multinomial"}, \code{"ordinal"} and \code{"gaussian"}. A specific link function is then chosen using the argument \code{link}, as explained below. Regression models are fitted using \code{\link{glm}}, \code{\link{coxph}}, \code{\link{multinom}}, \code{\link{polr}} or \code{\link{geeglm}}, respectively.}
\item{link}{specifies the specific link function between the variables in \code{numerator} or \code{denominator} and exposure, respectively. For \code{family="binomial"} (fitted using \code{\link{glm}}) valid alternatives are \code{"logit"}, \code{"probit"}, \code{"cauchit"}, \code{"log"} and \code{"cloglog"}. For \code{family="survival"} this argument is ignored, and Cox proportional hazards models are always used (fitted using \code{\link{coxph}}). For \code{family="multinomial"} this argument is ignored, and multinomial logistic regression models are always used (fitted using \code{\link{multinom}}). For \code{family="ordinal"} (fitted using \code{\link{polr}}) valid alternatives are \code{"logit"}, \code{"probit"}, \code{"cauchit"}, and \code{"cloglog"}. For \code{family="gaussian"} this argument is ignored, and GEE models with an identity link are always used (fitted using \code{\link{geeglm}}.}
\item{numerator}{specifies the right-hand side of the model used to estimate the elements in the numerator of the inverse probability weights. When left unspecified, unstabilized weights, with a numerator of 1, are estimated.}
\item{denominator}{specifies the right-hand side of the model used to estimate the elements in the denominator of the inverse probability weights.}
\item{id}{vector, uniquely identifying the units under observation (typically patients) within which the longitudinal measurements are taken.}
\item{tstart}{numerical vector, representing the starting time of follow-up intervals, using the counting process notation. This argument is only needed when \code{family="survival"}, otherwise it is ignored. The Cox proportional hazards models are fitted using counting process data. Since a switch in exposure level can occur at the start of follow-up, \code{tstart} should be negative for the first interval (with \code{timevar=0}) within each patient.}
\item{timevar}{numerical vector, representing follow-up time, starting at \code{0}. This variable is used as the end time of follow-up intervals, using the counting process notation, when \code{family="survival"}.}
\item{type}{specifies the type of exposure. Valid alternatives are \code{"first"} and \code{"all"}. With \code{type="first"}, weights are estimated up to the first switch from the lowest exposure value (typically \code{0} or the first factor level) to any other value. After this switch, weights will then be constant. Such a weight is e.g. used when estimating the effect of ``initiation of HAART'' on mortality (see example below). With \code{type="all"}, all time points are used to estimate weights. Currently, only \code{"first"} is implemented for \code{"binomial"}, \code{"survival"}, \code{"multinomial"} and \code{"ordinal"} families. Only value \code{"all"} is implemented only the \code{"gaussian"} family.}
\item{data}{dataframe containing \code{exposure}, variables in \code{numerator} and \code{denominator}, \code{id}, \code{tstart} and \code{timevar}.}
\item{corstr}{correlation structure, only needed when using \code{family="gaussian"}. Defaults to "ar1". See \code{\link{geeglm}} for details.}
\item{trim}{optional trim percentile (0-0.5). When specified, both untrimmed and trimmed weights are returned.}
\item{...}{further arguments passed to the functions used to estimate the \code{numerator} and \code{denominator} models (see \code{family} and \code{link}).}
}

\details{
Within each unit under observation i (usually patients), this function computes inverse probability weights at each time point j during follow-up. These weights are the cumulative product over all previous time points up to j of the ratio of two probabilities:
\itemize{
\item the numerator contains at each time point the probability of the observed exposure level given observed values of stabilization factors and the observed exposure history up to the time point before j. These probabilities are estimated using the model regressing \code{exposure} on the terms in \code{numerator}, using the link function indicated by \code{family} and \code{link}.
\item the denominator contains at each time point the probability of the observed exposure level given the observed history of time varying confounders up to j, as well as the stabilization factors in the numerator and the observed exposure history up to the time point before j. These probabilities are estimated using the model regressing \code{exposure} on the terms in \code{denominator}, using the link function indicated by \code{family} and \code{link}.}

When the models from which the elements in the numerator and denominator are predicted are correctly specified, and there is no unmeasured confounding, weighting observations ij by the inverse probability weights adjusts for confounding of the effect of the exposure of interest. On the weighted dataset a marginal structural model can then be fitted, quantifying the causal effect of the exposure on the outcome of interest.

With \code{numerator} specified, stabilized weights are computed, otherwise unstabilized weights with a numerator of 1 are computed. With a continuous exposure, using \code{family="gaussian"}, weights are computed using the ratio of predicted densities at each time point. Therefore, for \code{family="gaussian"} only stabilized weights can be used, since unstabilized weights would have infinity variance.
}

\value{
A list containing the following elements:
\item{ipw.weights }{vector containing inverse probability weights for each observation. Returned in the same order as the observations in \code{data}, to facilitate merging.}
\item{weights.trimmed }{vector containing trimmed inverse probability weights, only returned when \code{trim} is specified.}
\item{call }{the original function call.}
\item{selvar }{selection variable. With \code{type="first"}, \code{selvar=1} within each unit under observation, up to the first time point at which a switch from the lowest value of \code{exposure} to any other value is made, and \code{selvar=0} after the first switch. For \code{type="all"}, \code{selvar=1} for all measurements. The numerator and denominator models are fitted only on observations with \code{selvar=1}. Returned in the same order as observations in \code{data}, to facilitate merging.}
\item{num.mod }{the numerator model, only returned when \code{numerator} is specified.}
\item{den.mod }{the denominator model.}
}

\section{Missing values}{The \code{exposure} variable and the variables used in \code{numerator} and \code{denominator}, \code{id}, \code{tstart} and \code{timevar} should not contain missing values.}

\references{
Cole, S. R. & Hernán, M. A. (2008). Constructing inverse probability weights for marginal structural models. \emph{American Journal of Epidemiology}, \emph{168}(6), 656-664.

Robins, J. M., Hernán, M. A. & Brumback, B. A. (2000). Marginal structural models and causal inference in epidemiology. \emph{Epidemiology}, \emph{11}, 550-560.
}

\author{Willem M. van der Wal \email{w.m.vanderwal@amc.uva.nl}}
\note{
	%%  ~~further notes~~
}
%% ~Make other sections like Warning with \section{Warning }{....} ~

\seealso{\code{\link{basdat}}, \code{\link{haartdat}}, \code{\link{healthdat}}, \code{\link{ipwplot}}, \code{\link{ipwpoint}}, \code{\link{ipwtm}}, \code{\link{timedat}}, \code{\link{tstartfun}}.}

\examples{
########################################################################
#EXAMPLE 1

#Load longitudinal data from HIV positive individuals.
data(haartdat)

#CD4 count is confounder for the effect of initiation of HAART therapy on mortality.
#Estimate inverse probability weights to correct for confounding.
#Exposure allocation model is Cox proportional hazards model, with initiation of HAART as event.
temp <- ipwtm(
	exposure = haartind,
	family = "survival",
	numerator = ~ sex + age,
	denominator = ~ sex + age + cd4.sqrt,
	id = patient,
	tstart = tstart,
	timevar = fuptime,
	type = "first",
	data = haartdat)

#plot inverse probability weights
graphics.off()
ipwplot(weights = temp$ipw.weights, timevar = haartdat$fuptime, binwidth = 100, ylim = c(-1.5, 1.5), main = "Stabilized weights")

#Marginal structural model for the causal effect of initiation of HAART on mortality
#corrected for confounding by CD4 count using inverse probability weighting
#with robust standard error obtained using cluster().
summary(coxph(Surv(tstart, fuptime, event) ~ haartind + cluster(patient), data = haartdat, weights = temp$ipw.weights))	

#Uncorrected model
summary(coxph(Surv(tstart, fuptime, event) ~ haartind, data = haartdat))

########################################################################
#EXAMPLE 2

data(basdat)
data(timedat)

#Aim: to model the causal effect of the first instance of active tuberculosis (TB) after HIV seroconversion on mortality.
#Longitudinal CD4 count is a confounder as well as intermediate for the effect of TB.

#process original measurements
   table(duplicated(timedat[,c("id", "fuptime")])) #check for ties (not allowed)
   timedat$cd4.sqrt <- sqrt(timedat$cd4count) #take square root of CD4 because of skewness
   timedat <- merge(timedat, basdat[,c("id", "Ttb")], by = "id", all.x = TRUE) #add TB time to dataframe
   timedat$tb.lag <- ifelse(with(timedat, !is.na(Ttb) & fuptime > Ttb), 1, 0) #compute TB status
   cd4.lme <- lme(cd4.sqrt ~ fuptime + tb.lag, random = ~ fuptime | id, data = timedat) #longitudinal CD4-model

#build new dataset: rows corresponding to time points at which TB-status switches, and individual end times
   times <- sort(unique(c(basdat$Ttb, basdat$Tend)))
   startstop <- data.frame(
      id = rep(basdat$id, each = length(times)),
      fuptime = rep(times, nrow(basdat)))
   startstop <- merge(startstop, basdat, by = "id", all.x = TRUE) #add baseline data to dataframe
   startstop <- startstop[with(startstop, fuptime <= Tend),] #limit individual follow-up using Tend
   startstop$tstart <- tstartfun(id, fuptime, startstop) #compute tstart (see ?tstartfun)
   startstop$tb <- ifelse(with(startstop, !is.na(Ttb) & fuptime >= Ttb), 1, 0) #indicate TB status
   startstop$tb.lag <- ifelse(with(startstop, !is.na(Ttb) & fuptime > Ttb), 1, 0) #indicate TB status at previous time point
   startstop$event <- ifelse(with(startstop, !is.na(Tdeath) & fuptime >= Tdeath), 1, 0) #indicate death
   startstop$cd4.sqrt <- predict(cd4.lme, newdata = data.frame(id = startstop$id, fuptime = startstop$fuptime, tb.lag = startstop$tb.lag)) #impute CD4, based on TB status at previous time point. Note that lvcf could have been used also, but using the lme model smooths the measurements.

#compute inverse probability weights
   temp <- ipwtm(
        exposure = tb,
        family = "survival",
        numerator = ~ 1,
        denominator = ~ cd4.sqrt,
        id = id,
        tstart = tstart,
        timevar = fuptime,
        type = "first",
        data = startstop)
   summary(temp$ipw.weights)
   ipwplot(weights = temp$ipw.weights, timevar = startstop$fuptime, binwidth = 100)

#models
   summary(coxph(Surv(tstart, fuptime, event) ~ tb + cluster(id), data = startstop, weights = temp$ipw.weights)) #IPW-fitted MSM, using cluster() to obtain robust standard error estimate
   summary(coxph(Surv(tstart, fuptime, event) ~ tb, data = startstop)) #unadjusted
   summary(coxph(Surv(tstart, fuptime, event) ~ tb + cd4.sqrt, data = startstop)) #adjusted using conditioning: part of the effect of TB is adjusted away

#compute bootstrap CI for TB parameter (takes a few hours)
#   #taking into account the uncertainty introduced by modelling longitudinal CD4
#   #taking into account the uncertainty introduced by estimating the inverse probability weights
#   #robust with regard to weights unequal to 1
#   boot.fun <- function(data, index, data.tm){
#      data.samp <- data[index,]
#      data.samp$id.samp <- 1:nrow(data.samp)
#      data.tm.samp <- do.call("rbind", lapply(data.samp$id.samp, function(id.samp)cbind(data.tm[data.tm$id == data.samp$id[data.samp$id.samp == id.samp],], id.samp = id.samp)))
#      cd4.lme <- lme(cd4.sqrt ~ fuptime + tb.lag, random = ~ fuptime | id.samp, data = data.tm.samp)
#      times <- sort(unique(c(data.samp$Ttb, data.samp$Tend)))
#      startstop.samp <- data.frame(id.samp = rep(data.samp$id.samp, each = length(times)), fuptime = rep(times, nrow(data.samp)))
#      startstop.samp <- merge(startstop.samp, data.samp, by = "id.samp", all.x = TRUE)
#      startstop.samp <- startstop.samp[with(startstop.samp, fuptime <= Tend),]
#      startstop.samp$tstart <- tstartfun(id.samp, fuptime, startstop.samp)
#      startstop.samp$tb <- ifelse(with(startstop.samp, !is.na(Ttb) & fuptime >= Ttb), 1, 0)
#      startstop.samp$tb.lag <- ifelse(with(startstop.samp, !is.na(Ttb) & fuptime > Ttb), 1, 0)
#      startstop.samp$event <- ifelse(with(startstop.samp, !is.na(Tdeath) & fuptime >= Tdeath), 1, 0)
#      startstop.samp$cd4.sqrt <- predict(cd4.lme, newdata = data.frame(id.samp = startstop.samp$id.samp, fuptime = startstop.samp$fuptime, tb.lag = startstop.samp$tb.lag))
#      return(coef(coxph(Surv(tstart, fuptime, event) ~ tb, data = startstop.samp,
#         weights = ipwtm(
#              exposure = tb,
#              family = "survival",
#              numerator = ~ 1,
#              denominator = ~ cd4.sqrt,
#              id = id.samp,
#              tstart = tstart,
#              timevar = fuptime,
#              type = "first",
#              data = startstop.samp)$ipw.weights))[1])
#      }
#   bootres <- boot(data = basdat, statistic = boot.fun, R = 999, data.tm = timedat);bootres
#   boot.ci(bootres, type = "basic")
}

% Add one or more standard keywords, see file 'KEYWORDS' in the
% R documentation directory.
\keyword{htest}
\keyword{models}
